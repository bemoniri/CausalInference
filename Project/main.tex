\documentclass{article}
\input{structure.tex} 
\title{طرح اولیه‌ی پروژه‌ی درس استنتاج علّی\\
\vspace{0.5cm}
\textbf{\lr{A Review on Additive Noise Models:\\ Theorems and Learning Algorithms}}
} 
\author{بهراد منیری\\95109564\\ \texttt{bemoniri@live.com}}
\date{دانشکده‌ی مهندسی برق - دانشگاه صنعتی شریف}
%----------------------------------------------------------------------------------------

\begin{document}
\maketitle
\section{شرح مختصر طرح}
\noindent
در این پروژه قصد دارم تا  مقالات مربوط به 
\lr{Additive Noise Models}
را به طور دقیق بررسی کنم. هدف من بررسی مقالات این حوزه، از ابتدا تا الگوریتم‌های جدیدی مانند RESIT و مقایسه‌ی  عملکرد  روش‌ هرکدام از آنها بر داده‌های تجربی است. در نهایت نیز قصد دارم تا این الگوریتم‌ها را  با دیتاست‌های دیگری آزمایش کنم و  مقایسه‌ای از عملکرد آنها ارائه دهم.
 البته توجه من تنها به الگوریتم‌ها معطوف نخواهد بود.  قصد دارم که اثبات‌های مربوط به «قابل شناسایی بودن علّت در مدل‌های
\lr{ANM}»
را نیز یک بار به طور دقیق مطالعه کنم تا دید دقیق‌تری به شرایط  هر یک از این قضایا پیدا کنم.

\indent
\section{مقالات}
	مقالات زیر، مقالاتی هستند که قصد دارم در طی این پروژه به بررسی آنها بپردازم.

\underline{تمرکز من، بیشتر بر دو مقاله‌ی آخر خواهد بود.}


\begin{enumerate}
	
\begin{latin}
\bibitem{ANM}  
Hoyer, P., Janzing, D., Mooij, J., Peters, J. and Sch{\"o}lkopf, B.  (2008).
\textit{Nonlinear causal Discovery with Additive Noise Models}, \textbf{Advances  in  Neural  Information  Processing  Systems 21 (NIPS 2008)}.
\end{latin}
در این مقاله، برای دو متغیر که $SCM$ای به شکل زیر دارند اثبات می‌شود که با دیتای $observational$ می‌توان جهت درست علیّت را تشخیص داد. در واقع اثبات می کند که چگالی احتمال‌های معدودی هستند که اجازه‌ی وجود  $ANM$ در دو جهت را می‌دهند. در نهایت نیز روشی برای تشخیص این جهت ارائه شده و بر روی دیتای واقعی آزمایش می‌شود.
\begin{equation}
\begin{cases}
X = N_x \\
Y = f(X) + N_y \;\;\;\;\; N_x \bigCI N_y
\end{cases}
\end{equation}

\begin{latin}
\item Zhang, K. and Hyvärinen, A. (2009). 
\textit{On the Identifiability of the Post-Nonlinear Causal Model}, \textbf{}
\textbf{UAI '09 Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence}, pp. 647-655.
\end{latin}
در این مقاله، کار
\lr{Hoyer et al. (2008)}
به $SCM$هایی به شکل 
\begin{equation}
\begin{cases}
X = N_x \\
Y = g(f(X) + N_y) \;\;\;\;\; N_x \bigCI N_y
\end{cases}
\end{equation}
تعمیم می‌یابد و روشی برای یافتن توابع $f$ و $g$ از دیتای مشاهداتی ارائه می‌شود. در نهایت نیز این روش بر روی دیتای واقعی آزمایش می‌شود.

\begin{latin}
\item Peters, J., Janzing, D. and Sch{\"o}lkopf B. (2010).
\textit{Identifying Cause and Effect on Discrete Data using Additive Noise Models}, 
\textbf{Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics}, PMLR 9, pp. 597-604.
\end{latin}
این مقاله مسئله‌ای مشابه با مسئله‌ی 
\lr{Hoyer et al. (2008)}
را برای داده‌های گسسته بررسی می‌کند و نشان می‌دهد که در این حالت نیز توابع چگالی احتمال مشترک معدودی هستند که برای آنها ANM هایی در دو جهت وجود دارد. در ادامه الگوریتمی بهینه برای تشخیص علّت با دیتای محدود ارائه شده و با  داده‌های واقعی آزمایش می‌شود.

\begin{latin}
\bibitem{review}  
Peters, J. , Mooij, J., Janzing, D., and Sch{\"o}lkopf, B.  (2014).
\textit{Causal Discovery with Continuous Additive Noise Models}, \textbf{Journal of Machine Learning Research 15}, pp. 2009-2053.
\end{latin}
این مقاله در ابتدا مروری بسیار جامع بر مقالات قبل انجام می‌دهد و الگوریتمی عملی (و بهینه) به نام  $RESIT$ ارائه می‌دهد. این روش مبتنی بر 
\lr{independence score}
 است. در این الگوریتم هزینه‌ای برای افزایش تعداد یال‌ها قرار داده شده است تا در نهایت به گرافی برسیم که 
\lr{Causal Minimal}
است. 
این مقاله دو  الگوریتم دیگر را نیز بررسی می‌کند. الگوریتم اول مبتنی بر جستجوی حریسانه است. به این معنی که در هر مرحله گرافی «مجاور» با گراف مرحله‌ی حاضر را پیدا می‌کند که بیشترین score را داشته باشد. الگوریتم دوم نیز که برای گراف‌های بسیار کوچک استفاده می‌شود، بررسی تک‌تک گراف‌های ممکن و یافتن گرافی با بیشترین score است.

در انتها این مقاله بحث بسیار جامع و مفصلی در مورد بهره‌گیری این سه الگوریتم بر داده‌های واقعی انجام می‌دهد و آنها را با سایر روش‌ها مانند روش $PC$، که تنها CPDAG مربوطه را به دست می‌آورند انجام می‌دهد و در نهایت مشاهده می‌کند که در مجموع، روش RESIT بر دیگر روش‌ها برتری دارد.

\begin{latin}
	\bibitem{review}  
	Mooij, J., Peters, J.,  Janzing, D., Zscheischler, J. and Sch{\"o}lkopf, B.  (2016).
	\textit{Distinguishing Cause from Effect Using Observational Data:
		Methods and Benchmarks}, \textbf{Journal of Machine Learning Research 17}, pp. 1-102.
\end{latin}
این مقاله مجدداً به مرور ANM و IGCI می‌پردازد. تمرکز من در مطالعه‌ی این مقاله، بخش‌های مربوط به ANM خواهد بود. این مقاله،‌ الگوریتم‌های مربوط به ANM را برای بیش از صد دیتاست مختلف آزمایش می‌کند و مقایسه‌ی بسیار جامعی از آنها ارائه می‌دهد.  همچنین اثبات می‌کند که الگوریتم معرفی شده توسط 
\lr{Hoyer et al. (2008)}
سازگار است. این مقاله به دلیل بررسی بسیار بسیار جامع و عمیق مدل‌های ANM می‌تواند بسیار آموزنده باشد.
\end{enumerate}
\end{document}